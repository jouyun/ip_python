{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup\n",
    "- If I am doing any processing of files in a folder I like to import os and glob\n",
    "- import cellpose models for training of inferance\n",
    "- import something to read your images \n",
    "- import libraries to save your results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "from cellpose import models\n",
    "import napari\n",
    "import torch\n",
    "import nd2\n",
    "import numpy as np\n",
    "\n",
    "import skimage as ski\n",
    "\n",
    "import sutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the napari viewer to visualize images and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the image files to work with. Different path for Window, Mac, and Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 2048)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = ski.io.imread(\"files/cellpose/Data/01-yeast_many.tif\")\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the image to the napari viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'x' at 0x28e49554100>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the cellpose model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple way - On Workstation\n",
    "\n",
    "#### Model\n",
    "- cellpose has a number of pretrained models to use. Start with `cyto` or `cyto2` (even it is nuclei)\n",
    "- info about pretrained cellpose [models](https://cellpose.readthedocs.io/en/latest/models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Cellpose(gpu=True, model_type='cyto2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexible way - On Workstation or Mac\n",
    "\n",
    "Cellpose runs much faster on a gpu, and normally the only alternative is to run it on a cpu.  BUT there is a way to take advantage of the MacOS gpu that is a bit of a compromise.  If you are running on your own laptop you will want to use this instead.\n",
    "\n",
    "#### GPU setting\n",
    "- on windows or linux with an NVIDIA GPU, set `gpu=True``\n",
    "- on M1 or M2 mac, set `device=torch.device('mps')`\n",
    "- on old Mac or Windows without GPU, set `gpu=False` -- this will be slower\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'darwin':\n",
    "    d = torch.device('mps')\n",
    "    model = models.Cellpose(gpu=False, device=d, model_type='cyto2')\n",
    "else:\n",
    "    # change gpu=True if on windows, and get rid of device\n",
    "    model = models.Cellpose(gpu=True, model_type='cyto2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `model.eval`\n",
    "Parameters\n",
    "----------\n",
    "\n",
    "The basic options:\n",
    "- x : the image, can be a 2d numpy array, a list of numpy arrays,\n",
    "or a 3d numpy array\n",
    "- diameter : The approximate size of the object you are trying to segment\n",
    "- channels :\n",
    "    - [0, 0] for a grayscale image \n",
    "\n",
    "Returns\n",
    "-------\n",
    "- masks : An array or list of arrays with segmenation labels/masks\n",
    "- flows : A list of numpy arrays with fow\n",
    "- diams:  The diameter used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try cellpose with no parameter changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "masks, flows, styles, diams = model.eval(x, channels=[0, 0])\n",
    "diams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "masks is the label image we are interested in, the others we will talk about later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the results from cellpose a layers in napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'default diameter (30)' at 0x28e49543a60>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(x)\n",
    "viewer.add_labels(masks, name='default diameter (30)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what happens when the diameter is changed. What diameter is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'diameter 45' at 0x28e4bb9f190>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "masks, flows, styles, diams = model.eval(x, channels=[0, 0],\n",
    "                                         diameter=45)\n",
    "\n",
    "viewer.add_labels(masks, name='diameter 45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'diameter 15' at 0x28e3e179390>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "masks, flows, styles, diams = model.eval(x, channels=[0, 0],\n",
    "                                         diameter=15)\n",
    "\n",
    "viewer.add_labels(masks, name='diameter 15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flow_threshold and cellprob_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mchannels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mchannel_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mz_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdiameter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdo_3D\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0manisotropy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnet_avg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0maugment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtile_overlap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0minterp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mflow_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcellprob_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mstitch_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrescale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprogress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmodel_loaded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "run cellpose and get masks\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "x: list or array of images\n",
      "    can be list of 2D/3D images, or array of 2D/3D images, or 4D image array\n",
      "\n",
      "batch_size: int (optional, default 8)\n",
      "    number of 224x224 patches to run simultaneously on the GPU\n",
      "    (can make smaller or bigger depending on GPU memory usage)\n",
      "\n",
      "channels: list (optional, default None)\n",
      "    list of channels, either of length 2 or of length number of images by 2.\n",
      "    First element of list is the channel to segment (0=grayscale, 1=red, 2=green, 3=blue).\n",
      "    Second element of list is the optional nuclear channel (0=none, 1=red, 2=green, 3=blue).\n",
      "    For instance, to segment grayscale images, input [0,0]. To segment images with cells\n",
      "    in green and nuclei in blue, input [2,3]. To segment one grayscale image and one\n",
      "    image with cells in green and nuclei in blue, input [[0,0], [2,3]].\n",
      "\n",
      "channel_axis: int (optional, default None)\n",
      "    if None, channels dimension is attempted to be automatically determined\n",
      "\n",
      "z_axis: int (optional, default None)\n",
      "    if None, z dimension is attempted to be automatically determined\n",
      "\n",
      "invert: bool (optional, default False)\n",
      "    invert image pixel intensity before running network (if True, image is also normalized)\n",
      "\n",
      "normalize: bool (optional, default True)\n",
      "    normalize data so 0.0=1st percentile and 1.0=99th percentile of image intensities in each channel\n",
      "\n",
      "diameter: float (optional, default 30.)\n",
      "    if set to None, then diameter is automatically estimated if size model is loaded\n",
      "\n",
      "do_3D: bool (optional, default False)\n",
      "    set to True to run 3D segmentation on 4D image input\n",
      "\n",
      "anisotropy: float (optional, default None)\n",
      "    for 3D segmentation, optional rescaling factor (e.g. set to 2.0 if Z is sampled half as dense as X or Y)\n",
      "\n",
      "net_avg: bool (optional, default False)\n",
      "    runs the 4 built-in networks and averages them if True, runs one network if False\n",
      "\n",
      "augment: bool (optional, default False)\n",
      "    tiles image with overlapping tiles and flips overlapped regions to augment\n",
      "\n",
      "tile: bool (optional, default True)\n",
      "    tiles image to ensure GPU/CPU memory usage limited (recommended)\n",
      "\n",
      "tile_overlap: float (optional, default 0.1)\n",
      "    fraction of overlap of tiles when computing flows\n",
      "\n",
      "resample: bool (optional, default True)\n",
      "    run dynamics at original image size (will be slower but create more accurate boundaries)\n",
      "\n",
      "interp: bool (optional, default True)\n",
      "        interpolate during 2D dynamics (not available in 3D) \n",
      "        (in previous versions it was False)\n",
      "\n",
      "flow_threshold: float (optional, default 0.4)\n",
      "    flow error threshold (all cells with errors below threshold are kept) (not used for 3D)\n",
      "\n",
      "cellprob_threshold: float (optional, default 0.0)\n",
      "    all pixels with value above threshold kept for masks, decrease to find more and larger masks\n",
      "\n",
      "min_size: int (optional, default 15)\n",
      "        minimum number of pixels per mask, can turn off with -1\n",
      "\n",
      "stitch_threshold: float (optional, default 0.0)\n",
      "    if stitch_threshold>0.0 and not do_3D and equal image sizes, masks are stitched in 3D to return volume segmentation\n",
      "\n",
      "rescale: float (optional, default None)\n",
      "    if diameter is set to None, and rescale is not None, then rescale is used instead of diameter for resizing image\n",
      "\n",
      "progress: pyqt progress bar (optional, default None)\n",
      "    to return progress bar status to GUI\n",
      "\n",
      "model_loaded: bool (optional, default False)\n",
      "    internal variable for determining if model has been loaded, used in __main__.py\n",
      "\n",
      "Returns\n",
      "-------\n",
      "masks: list of 2D arrays, or single 3D array (if do_3D=True)\n",
      "        labelled image, where 0=no masks; 1,2,...=mask labels\n",
      "\n",
      "flows: list of lists 2D arrays, or list of 3D arrays (if do_3D=True)\n",
      "    flows[k][0] = XY flow in HSV 0-255\n",
      "    flows[k][1] = XY flows at each pixel\n",
      "    flows[k][2] = cell probability (if > cellprob_threshold, pixel used for dynamics)\n",
      "    flows[k][3] = final pixel locations after Euler integration \n",
      "\n",
      "styles: list of 1D arrays of length 256, or single 1D array (if do_3D=True)\n",
      "    style vector summarizing each image, also used to estimate size of objects in image\n",
      "\n",
      "diams: list of diameters, or float (if do_3D=True)\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\smc\\appdata\\local\\miniforge3\\envs\\napari\\lib\\site-packages\\cellpose\\models.py\n",
      "\u001b[1;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "model.eval?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have cellprob_threshold and flow_threshold we can tweak.\n",
    "\n",
    "flow_threshold:  defaults to 0.4, range is 0->3.  Higher values let more objects through, where the shape is less solidly known.\n",
    "\n",
    "cellprob_threshold:  defaults to 0.0, range is -10->10.  Lower values let more of an existing object through, so objects end up larger.  At high values will start to remove objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/cellpose/cellpose_params.png\" width=\"950\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'diameter 45, cellprob 6' at 0x28e3eb6a110>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks, flows, styles, diams = model.eval(x, channels=[0, 0],\n",
    "                                             diameter=45,\n",
    "                                             cellprob_threshold=-6)\n",
    "viewer.add_labels(masks, name='diameter 45, cellprob -6')\n",
    "\n",
    "masks, flows, styles, diams = model.eval(x, channels=[0, 0],\n",
    "                                                diameter=45,\n",
    "                                                cellprob_threshold=6)\n",
    "viewer.add_labels(masks, name='diameter 45, cellprob 6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
