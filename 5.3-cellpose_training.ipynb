{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from skimage import io\n",
    "import skimage as ski\n",
    "from cellpose import models\n",
    "import napari\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block is completely optional, we use it to see a little under the hood of what cellpose is doing during the training but it is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = logging.getLogger()\n",
    "r.setLevel(logging.INFO)\n",
    "h = logging.StreamHandler(sys.stdout)\n",
    "h.setLevel(logging.INFO)\n",
    "r.addHandler(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These images will be 2 channel, the first is the raw data and the 2nd the labeled image we annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob.glob(\"files/Training/training_images/*.tif\"))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the images for training. It is of the utmost importance that the masks be label images, not binary images.\n",
    "I know some of the images in this traing seet are binary, so run the skimage label on the seconds channel to turn it into a labeled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list()\n",
    "masks = list()\n",
    "\n",
    "for f in files:\n",
    "    x = tifffile.imread(f)\n",
    "    images.append(x[0])\n",
    "    masks.append(ski.measure.label(x[1].astype(np.uint16)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellpose wants a list of our raw images and a list of our label images so we split them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[5].max(), masks[5].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Use models.CellposeModel now instead of models.Cellpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> cyto2 << model set to be used\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      ">>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n"
     ]
    }
   ],
   "source": [
    "if sys.platform == 'darwin':\n",
    "    d = torch.device('mps')\n",
    "    model = models.CellposeModel(gpu=False, device=d, model_type='cyto2')\n",
    "else:\n",
    "    # change gpu=True if on windows, and get rid of device\n",
    "    model = models.CellposeModel(gpu=True, model_type='cyto2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellpose automatically figures out what diameter would be good to use for downsampling our image based on the average size of the objects in the training data we provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:30<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> median diameter set to = 30\n",
      ">>>> mean of training label mask diameters (saved to model) 183.167\n",
      ">>>> training network with 2 channel input <<<<\n",
      ">>>> LR: 0.20000, batch_size: 16, weight_decay: 0.00001\n",
      ">>>> ntrain = 23\n",
      ">>>> nimg_per_epoch = 24\n",
      "Epoch 0, Time  2.5s, Loss 0.9245, LR 0.0000\n",
      "saving network parameters to models\\models/custom\n",
      "Epoch 5, Time 10.7s, Loss 0.5197, LR 0.1111\n",
      "Epoch 10, Time 18.5s, Loss 0.2215, LR 0.2000\n",
      "Epoch 20, Time 34.2s, Loss 0.1712, LR 0.2000\n",
      "Epoch 30, Time 49.7s, Loss 0.1485, LR 0.2000\n",
      "Epoch 40, Time 65.2s, Loss 0.1422, LR 0.2000\n",
      "Epoch 50, Time 81.3s, Loss 0.1342, LR 0.2000\n",
      "Epoch 60, Time 97.4s, Loss 0.1318, LR 0.2000\n",
      "Epoch 70, Time 112.5s, Loss 0.1291, LR 0.2000\n",
      "Epoch 80, Time 128.9s, Loss 0.1255, LR 0.2000\n",
      "Epoch 90, Time 144.7s, Loss 0.1243, LR 0.2000\n",
      "saving network parameters to models\\models/custom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models\\\\models/custom'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(images, masks, channels=[0, 0], save_path='models', n_epochs=100,\n",
    "            nimg_per_epoch=24, model_name='custom', batch_size=16,\n",
    "            min_train_masks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check how well the model is doing.\n",
    "\n",
    "This model only has 3 return values, so get rid of the last "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 7\n",
    "x = tifffile.imread(files[idx])\n",
    "test_masks, flows, _ = model.eval(x[0], channels=[0, 0],\n",
    "                             cellprob_threshold=0, flow_threshold=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'test_masks' at 0x20231979120>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(x[0])\n",
    "viewer.add_labels(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image [1]' at 0x202361a5060>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(flows[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
