{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from skimage import io\n",
    "import skimage as ski\n",
    "from cellpose import models\n",
    "import napari\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logging so the cellpose will print information during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:80ch; margin:10;\">\n",
    "Use glob to find tiff images in a folders. These are the images we need to create manual labels of so a custom training model can be built.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = sorted(glob.glob(\"files/Training/sample_images/*.tif\"))\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 2048)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = images[6]\n",
    "x = tifffile.imread(fname)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'x' at 0x2695e3a9cf0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see how well cellpose does on this image.\n",
    "- get a model just like before\n",
    "- run eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == 'darwin':\n",
    "    d = torch.device('mps')\n",
    "    model = models.Cellpose(gpu=False, device=d, model_type='cyto2')\n",
    "else:\n",
    "    # change gpu=True if on windows, and get rid of device\n",
    "    model = models.Cellpose(gpu=True, model_type='cyto2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masks, flows, _, _ = model.eval(x, channels=[0, 0], diameter=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'masks' at 0x26972109180>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are mistakes in the mask, so labels will need to be created manually.\n",
    "Let's look at the annotation tools in the label layer.\n",
    "\n",
    "\n",
    "....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The napari viewer has a lot of useful tools for annotating images.  We will always be using a labels layer to do so.  You can create one next to the trash can icon (looks like a luggage tag).  \n",
    "\n",
    "Once a labels layer is selected, you paint individual objects with the paint brush/fill tools.  The way we denote one object as being distinct from another is by making sure we paint with a different color on each object.  The \"label\" slider at the top of the bar tells us which object we are currently painting.  By pressing the \"m\" key on our keyboard we can automatically select the next unused index:  very handy for moving on to a next object.  \n",
    "\n",
    "The other drawing tools are above the \"label\" slider:  erasure, paintbrush, fill, eye dropper, navigate.  By mousing over them you can see that each has a keyboard shortcut key (the numeric keys 1, 2, 3, 4 etc.)\n",
    "\n",
    "Sometimes we have to start from scratch:  a completely blank labels layer where we paint each and every object in the image, but frequently we can piggyback on something that is already halfway there like thresholding or cellpose itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label images for training\n",
    "- View image\n",
    "- model.eval the image\n",
    "- add labels\n",
    "- edit the labels\n",
    "- get labels out of the viewer\n",
    "- create a stack with the image and the mask\n",
    "- save to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual annotation (assisted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting our label image for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless whether you used purely manual or assisted manual, you will need to save your labels layer to be used later with cellpose for training.  Assuming the most recent (top) layer of napari is our labels layer that we want to save, we can access its data with viewer.layers[-1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2048, 2048), dtype('uint16'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = viewer.layers[-1].data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as in last class, we will combine the two single channel images into one double channel image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx = np.stack([x, masks])\n",
    "tx.shape, tx.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = os.path.basename(fname)\n",
    "tifffile.imwrite(f\"Data/Training/for_training/{bn}\", tx.astype(np.uint16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
